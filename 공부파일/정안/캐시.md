

# ❓ 도입 배경 및 필요성

### 현재 상황

![1](images/1.png)

* 올리브영은 연 4회 선착순 쿠폰 발급 이벤트를 진행하며, 0시·12시에 트래픽이 급격하게 증가함
* 기존 쿠폰 발급 프로세스는 아래와 같았음

![2](images/2.png)

* 쿠폰 발급 요청 이후 모든 단계가 하나의 동기(Sync) 방식으로 처리됨
  (유효성 검사 → DB 기록 → 처리 완료 전송)

### 현재 구조의 장점 & 문제점

**장점**

* 로직 전체가 일체형(동기)으로 구성되어 높은 트래픽에도 순차적으로 안정적으로 처리됨
* **DB 일관성과 신뢰성** 보장

**단점**

* 모든 요청이 큐처럼 순차 처리되기 때문에, 뒤에 있는 사용자는 **Response Time 악화**
* 사용자 경험 측면에서 불리함

### 목표하는 개선 방향

* 사용자 경험 개선을 위해 **Response Time 단축** 필요
* 기존 일체형 구조를 분리하여 비동기 방식으로 개선할 필요 있음


### Redis + RabbitMQ 혼합 모델

* **Redis:** 초고속 선착순 검증 (Lua Script + In-Memory)
* **RabbitMQ:** 메시지 보존, 재시도, ACK 보장

| 역할    | Redis            | RabbitMQ       |
| ----- | ---------------- | -------------- |
| 핵심 기능 | 트래픽 컷오프 / 선착순 판단 | 안정적 DB 처리      |
| 장점    | 초저지연             | 메시지 전달 보장(ACK) |

![15](images/15.png)

### 최종 흐름

1. Redis가 선착순 판단 후 합격 요청만 RabbitMQ로 전달
2. RabbitMQ가 안정적으로 Worker에게 메시지 전달
3. Worker가 DB에 반영


# 💾 Redis 캐시 전략 정리
### Redis가 캐시로 사용되는 이유

일반적으로 "캐시"는 CPU와 메모리 사이에서 데이터를 빠르게 가져오기 위한 구조이지만,
Redis는 디스크 기반 DB보다 훨씬 빠른 인메모리 캐시로 사용된다.

Redis는 메모리에 데이터를 저장하여 초고속 응답 성능을 제공

단, 메모리는 디스크보다 용량이 작고 휘발성이므로 어떤 데이터를 얼마나 오래 저장할지 전략이 필요

캐시와 DB의 데이터가 달라질 수 있으므로 정합성 이슈 고려 필요

### 용어 정리

* cache hit : 요청한 데이터가 캐시에 존재할 때
* cache miss : 캐시에 없어서 DB를 조회해야 할 때

캐시의 목적은 DB 부하 감소 + 응답 속도 개선이지만,
이를 위해서는 읽기/쓰기 전략을 적절히 조합해야 한다.

# 📖 캐시 읽기 전략 (Read Strategies)
### 1. Look Aside (= Cache Aside)

캐시 먼저 조회 → 없으면 DB에서 조회하여 캐시에 저장

읽기 요청이 많고, 초기에 캐시에 데이터가 없는 경우 DB 부담이 큼
→ Cache Warming 필요

캐시 장애 시 DB로 우회 가능하여 서비스 전체 영향이 적음

특징

캐시와 DB가 분리되어 있어 유연함

TTL 관리 필요

데이터 정합성이 깨질 수 있음

### 2. Read Through

항상 캐시를 통해서만 조회

캐시에 없으면 캐시가 직접 DB에서 조회 후 캐시에 저장

**특징**

캐시가 DB 접근을 대신하므로 일관성 좋음

캐시에 장애 발생 시 → 전체 장애 가능
→ Replication / Cluster 구성 필수

Cache Warming 역시 필요

# 📝 캐시 쓰기 전략 (Write Strategies)
### 1. Write Back (= Write Behind)

쓰기 요청을 캐시에 먼저 저장

일정 주기마다 캐시가 DB로 한번에 반영 (비동기)

**장점**

DB 부하 감소

Write가 매우 많은 서비스에 적합

**단점**

캐시에 장애 나면 미반영 데이터 유실 위험

자주 사용되지 않는 데이터가 캐시에 오래 남을 수 있음

### 2. Write Through

캐시에 먼저 쓰고, 그 즉시 DB에도 저장 (동기)

**장점**

항상 최신 데이터 유지

캐시와 DB 정합성이 매우 높음

**단점**

요청마다 DB도 접근하므로 성능 저하

불필요한 데이터도 캐시에 계속 남을 수 있음

### 3. Write Around

모든 쓰기를 DB에만 저장

캐시는 오염시키지 않음

**특징**

한번만 쓰이고 거의 읽히지 않는 데이터에 적합

수정 시 캐시 반영이 안 되어 정합성 이슈 발생 가능

# 🔀 캐시 읽기 + 쓰기 전략 조합
Look Aside + Write Around
가장 일반적이며 많이 사용되는 조합.

Read Through + Write Around
항상 DB에 먼저 반영하고 캐시에서 읽을 때 DB → 캐시 흐름으로
정합성 안전장치 강화.

Read Through + Write Through
항상 최신 데이터 유지 + 데이터 정합성 최고 수준.

#  📦 캐시 저장 방식

캐시는 자주 읽히고 잘 변하지 않는 데이터를 저장해야 효과적
→ Cache Hit Ratio 향상

Redis는 휘발성이며 데이터 유실 가능
→ 민감한 데이터 저장 지양

파레토 법칙(8:2 법칙)
전체 데이터의 20%만 캐시해도 80%의 요청을 커버하는 경우가 많다.

# ⏳ 캐시 제거(만료) 방식

캐시는 일반적으로 영구 저장소(DB)의 복사본으로 동작하므로
만료(TTL) 정책이 반드시 필요하다.

TTL이 너무 짧으면

캐시 이점이 거의 없음

Cache Stampede 발생 가능
(많은 요청이 동시에 캐시 미스 → DB에 몰림 → 성능 저하 악순환)

Stampede 방지 기법

mutex-lock (단일 요청만 DB 접근 허용)

TTL + 랜덤값 혼합

Soft TTL

TTL이 너무 길면

메모리 부족

오래된 데이터가 계속 사용될 가능성

# 🔒 캐시 공유·동시성 지침

캐시는 여러 서버 인스턴스에서 공유됨

수정 중 충돌이 일어나면 안 됨 → race condition 위험

Redis는 싱글 스레드 기반이라
→ 명령이 순차적으로 처리되어 기본적인 race condition이 없음

대규모 트래픽에서는 Redis Cluster로 샤딩 운영

# ♻️ 캐시 가용성 지침

캐시는 빠른 응답을 위해 존재하는 컴포넌트

캐시 장애로 인해 전체 서비스가 중단되면 안 됨
→ 보통 캐시 장애 = 성능 저하, 서비스 자체는 DB로 우회해 운영 가능

(Write Through 기반이면 DB와 캐시 데이터가 동일하다는 가정하에 가능)

# 🧩 Redis 특성과 구조

Redis는 다양한 Collection Type을 제공함

List

Set

Sorted Set

Hash

Stream

Bitmap 등

또한 다음 특징을 가진다:

싱글스레드 기반 → 명령 실행이 Atomic

Redis Cluster로 샤딩 구조 지원

Master–Replica 구조로 고가용성 확보

RDB/AOF 기반 persistence 지원 → 재시작 시 데이터 복구 가능

# 🔥 Hot Key 문제 (특정 키에 요청 집중)

Redis 실무에서 가장 많이 발생하는 이슈 중 하나.

✔ Hot Key란?

특정 key가 너무 많이 요청되면
해당 key가 저장된 Redis 노드만 과부하됨 → 장애 발생

예:

product:1 조회가 전체 트래픽의 40%를 차지하는 경우

같은 key에 대한 반복적인 GET 요청

TTL 만료되면 동시에 수천 요청이 DB로 쏠려 Stampede 발생

해결 전략

Key Sharding (hash suffix 붙이기)

Local Cache(Caffeine 등)와 혼합

Lua Script로 atomic 제어

Redis Cluster로 분산 저장
